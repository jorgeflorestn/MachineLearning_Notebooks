{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotEncoder(target):\n",
    "    n_classes = np.unique(target).shape[0]\n",
    "    y_encode = np.zeros((target.shape[0], n_classes))\n",
    "    for idx, val in enumerate(y):\n",
    "        y_encode[idx, val] = 1.0\n",
    "    return y_encode\n",
    "\n",
    "def sigmoid(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis = 1, keepdims = True)\n",
    "\n",
    "\n",
    "def model_fit(data, target, eta=0.55, iterations=100000):\n",
    "    m = len(target)\n",
    "    print(f'target: ', m)\n",
    "    \n",
    "    theta = np.random.randn(data.shape[1], target.shape[1])\n",
    "    print(f'theta: \\n', theta)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        gradients = (1/m) * (data.T @ (sigmoid(data @ theta) - target))\n",
    "        theta = theta - eta * gradients\n",
    "    print(f'\\n',theta)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, target, train_q = 35):\n",
    "    if (train_q < 0) or (train_q > 49): return 0, 0, 0, 0\n",
    "    \n",
    "    data_train = np.concatenate((data[0:train_q], data[50:(train_q + 50)], data[100:(train_q + 100)]))\n",
    "    data_test = np.concatenate ((data[train_q:50], data[(train_q + 50):100], data[(train_q + 100):150]))\n",
    "    target_train = np.concatenate((target[0:train_q], target[50:(train_q + 50)], target[100:(train_q + 100)]))\n",
    "    target_test = np.concatenate ((target[train_q:50], target[(train_q + 50):100], target[(train_q + 100):150]))\n",
    "    \n",
    "    return data_train, data_test, target_train, target_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "X_c = np.c_[np.ones((len(X), 1)), X]\n",
    "y_c = oneHotEncoder(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 5) (45, 5) (105, 3) (45, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = split_train_test(X_c, y_c)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_fit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[39m=\u001b[39m model_fit(X_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_fit' is not defined"
     ]
    }
   ],
   "source": [
    "a = model_fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(sepal_length, sepal_width, petal_length, petal_width, weights):\n",
    "    list1 = [0, 0, 0]\n",
    "    \n",
    "    for i in range(len(list1)):\n",
    "        a0 = weights.T[i][0]\n",
    "        a1 = weights.T[i][1]\n",
    "        a2 = weights.T[i][2]\n",
    "        a3 = weights.T[i][3]\n",
    "        a4 = weights.T[i][4]\n",
    "        list1[i] = np.exp(a0 + a1 * sepal_length + a2 * sepal_width + a3 * petal_length + a4 * petal_width)\n",
    "    maxP = np.argmax([z / sum(list1) for z in list1])\n",
    "    pred = [0, 0, 0]\n",
    "    pred[maxP] = 1\n",
    "    return pred\n",
    "    #return [z / sum(list1) for z in list1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predict(data, target, weights):\n",
    "    predict_list = []\n",
    "    test_list = []\n",
    "    for i in data:\n",
    "        predict_list.append(np.argmax(model_test(i[0], i[1], i[2], i[3], weights)))\n",
    "    for j in target:\n",
    "        test_list.append(np.argmax(j))\n",
    "    num = 0\n",
    "    for k in range(len(predict_list)):\n",
    "        if predict_list[k] == test_list[k]: num = num +1\n",
    "        \n",
    "    final_list = np.array([predict_list, test_list], ndmin=2)\n",
    "    effi = num/len(predict_list)\n",
    "    return final_list, effi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 0 2 2 2 2 2 0 2 2 2 2 1 2 2 2 2 2 2 2\n",
      "  2 2 2 2 2 2 2 2 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2\n",
      "  2 2 2 2 2 2 2 2 2]] 0.35555555555555557\n"
     ]
    }
   ],
   "source": [
    "predictions, efficiency = model_predict(X_test, y_test, a)\n",
    "\n",
    "print(predictions, efficiency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
